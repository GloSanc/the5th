{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. example of street map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-6b6b03c00138>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-6b6b03c00138>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    street_type{street_type}+=1\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re  # python regular expresion module\n",
    "\n",
    "osm_file = open (\"chicago_abrev.osm\", \"r\")\n",
    "\n",
    "street_type_re = re.compile (r'\\S+\\.?$', re.IGNORECASE) #regualar expresion @ we are going to match a sequece\n",
    "                                # \\S+ of non-white space chareacters optionaly followed by a period\n",
    "                                 # \\.? this is to catch abbreviations like ave or st  a period\n",
    "                                 # $ this match must occur at the end of the string \n",
    "street_type=defaultdict (int)\n",
    "\n",
    "def audit_street_type (street_type, street_name):\n",
    "    m=street_type_re.search(street_name)  # recognize type\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        street_type{sstreet_type}+=1\n",
    "        \n",
    "def print_sorted_dic(d):\n",
    "    keys=d.keys()\n",
    "    keys= sorted (keys, key= lambda s@ s.lower())\n",
    "    for k in keys:\n",
    "        v=d[k]\n",
    "        print (\"%s:%d\" % (k,v))\n",
    "        \n",
    "def is_street_name(elem):\n",
    "    return (elem.tag==\"tag\") and (elem.attrib['k']==\"addr:street\")\n",
    "\n",
    "def audit ():\n",
    "    for event, elem in ET.interparse(osm_file):    #looping throuth this XML file using the Sax parser that                               \n",
    "                                                # part of the element tree module. \n",
    "                                                # each loop is asking if there is a street name and creating \n",
    "                                                # a record of all street type that we find in this data set \n",
    "                                                \n",
    "                    \n",
    "        if is_street_name(elem):\n",
    "            audit_street_type(street_type, elem.attrib['v'])\n",
    "    print_sorted_dict (street_types)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    audit()\n",
    "        \n",
    "        # once we have all the street type in the dataset, we could decide how we want to clean that\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Quiz correcting validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'autos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-675cd9686fdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-675cd9686fdd>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mprocess_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_GOOD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_BAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-675cd9686fdd>\u001b[0m in \u001b[0;36mprocess_file\u001b[1;34m(input_file, output_good, output_bad)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_good\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_bad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'autos.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "\"\"\"\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "\n",
    "        #COMPLETE THIS FUNCTION\n",
    "\n",
    "\n",
    "\n",
    "    # This is just an example on how you can use csv.DictWriter\n",
    "    # Remember that you have to output 2 files\n",
    "    with open(output_good, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in YOURDATA:\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>rdf-schema#label</th>\n",
       "      <th>rdf-schema#comment</th>\n",
       "      <th>assembly_label</th>\n",
       "      <th>assembly</th>\n",
       "      <th>automobilePlatform_label</th>\n",
       "      <th>automobilePlatform</th>\n",
       "      <th>bodyStyle_label</th>\n",
       "      <th>bodyStyle</th>\n",
       "      <th>class_label</th>\n",
       "      <th>...</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>width</th>\n",
       "      <th>point</th>\n",
       "      <th>22-rdf-syntax-ns#type_label</th>\n",
       "      <th>22-rdf-syntax-ns#type</th>\n",
       "      <th>wgs84_pos#lat</th>\n",
       "      <th>wgs84_pos#long</th>\n",
       "      <th>depiction_label</th>\n",
       "      <th>depiction</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URI</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#label</td>\n",
       "      <td>http://www.w3.org/2000/01/rdf-schema#comment</td>\n",
       "      <td>http://dbpedia.org/ontology/assembly</td>\n",
       "      <td>http://dbpedia.org/ontology/assembly</td>\n",
       "      <td>http://dbpedia.org/ontology/automobilePlatform</td>\n",
       "      <td>http://dbpedia.org/ontology/automobilePlatform</td>\n",
       "      <td>http://dbpedia.org/ontology/bodyStyle</td>\n",
       "      <td>http://dbpedia.org/ontology/bodyStyle</td>\n",
       "      <td>http://dbpedia.org/ontology/class</td>\n",
       "      <td>...</td>\n",
       "      <td>http://dbpedia.org/ontology/wheelbase</td>\n",
       "      <td>http://dbpedia.org/ontology/width</td>\n",
       "      <td>http://www.georss.org/georss/point</td>\n",
       "      <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</td>\n",
       "      <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</td>\n",
       "      <td>http://www.w3.org/2003/01/geo/wgs84_pos#lat</td>\n",
       "      <td>http://www.w3.org/2003/01/geo/wgs84_pos#long</td>\n",
       "      <td>http://xmlns.com/foaf/0.1/depiction</td>\n",
       "      <td>http://xmlns.com/foaf/0.1/depiction</td>\n",
       "      <td>http://xmlns.com/foaf/0.1/name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URI</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>owl#Thing</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>owl#Thing</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>...</td>\n",
       "      <td>XMLSchema#double</td>\n",
       "      <td>XMLSchema#double</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>owl#Class</td>\n",
       "      <td>XMLSchema#float</td>\n",
       "      <td>XMLSchema#float</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "      <td>owl#Thing</td>\n",
       "      <td>XMLSchema#string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.w3.org/2002/07/owl#Thing</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#Thing</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://dbpedia.org/ontology/Automobile</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#Thing</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#double</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#double</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#Class</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#float</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#float</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#Thing</td>\n",
       "      <td>http://www.w3.org/2001/XMLSchema#string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbpedia.org/resource/Crawler-transporter</td>\n",
       "      <td>Crawler-transporter</td>\n",
       "      <td>The crawler-transporters are a pair of tracked...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.7472</td>\n",
       "      <td>28.58808 -80.65521</td>\n",
       "      <td>{automobile|mean of transportation|Product|_Fe...</td>\n",
       "      <td>{http://dbpedia.org/ontology/Automobile|http:/...</td>\n",
       "      <td>28.5881</td>\n",
       "      <td>-80.6552</td>\n",
       "      <td>Crawler-Transporter.jpg</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>Crawler-transporter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbpedia.org/resource/Ford_GT40</td>\n",
       "      <td>Ford GT40</td>\n",
       "      <td>The Ford GT40 is a high performance American-B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{Coupé|Roadster (automobile)}</td>\n",
       "      <td>{http://dbpedia.org/resource/Coup%C3%A9|http:/...</td>\n",
       "      <td>{Group 4 (racing)|Group 6 (racing)}</td>\n",
       "      <td>...</td>\n",
       "      <td>2.413</td>\n",
       "      <td>1.778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{automobile|mean of transportation|Product|owl...</td>\n",
       "      <td>{http://dbpedia.org/ontology/Automobile|http:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GT40_at_Goodwood.jpg</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>Ford GT40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://dbpedia.org/resource/Mazda_MX-5</td>\n",
       "      <td>Mazda MX-5</td>\n",
       "      <td>The MX-5 also known as Miata in North America ...</td>\n",
       "      <td>{Hiroshima|Japan}</td>\n",
       "      <td>{http://dbpedia.org/resource/Hiroshima|http://...</td>\n",
       "      <td>Mazda N platform</td>\n",
       "      <td>http://dbpedia.org/resource/Mazda_N_platform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roadster (automobile)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{automobile|mean of transportation|Product|owl...</td>\n",
       "      <td>{http://dbpedia.org/ontology/Automobile|http:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011_Mazda_MX-5_PRHT_--_04-28-2011.jpg</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>{Eunos Roadster|Mazda MX-5|Mazda MX-5 Miata|Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://dbpedia.org/resource/Porsche_928</td>\n",
       "      <td>Porsche 928</td>\n",
       "      <td>The Porsche 928 is a sports-GT car that was so...</td>\n",
       "      <td>{Germany|Stuttgart}</td>\n",
       "      <td>{http://dbpedia.org/resource/Germany|http://db...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coupé</td>\n",
       "      <td>http://dbpedia.org/resource/Coup%C3%A9</td>\n",
       "      <td>Grand tourer</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{automobile|mean of transportation|Product|owl...</td>\n",
       "      <td>{http://dbpedia.org/ontology/Automobile|http:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987_Porsche_928_S4_front.jpg</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>Porsche 928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://dbpedia.org/resource/Porsche_924</td>\n",
       "      <td>Porsche 924</td>\n",
       "      <td>The Porsche 924 is a sports car produced by Po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2+2 (car body style)</td>\n",
       "      <td>http://dbpedia.org/resource/2+2_(car_body_style)</td>\n",
       "      <td>Sports car</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{automobile|mean of transportation|Product|owl...</td>\n",
       "      <td>{http://dbpedia.org/ontology/Automobile|http:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977-1982_Porsche_924_coupe_(2011-04-28)_01.jpg</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>Porsche 924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               URI  \\\n",
       "0                                              URI   \n",
       "1                                              URI   \n",
       "2              http://www.w3.org/2002/07/owl#Thing   \n",
       "3  http://dbpedia.org/resource/Crawler-transporter   \n",
       "4            http://dbpedia.org/resource/Ford_GT40   \n",
       "5           http://dbpedia.org/resource/Mazda_MX-5   \n",
       "6          http://dbpedia.org/resource/Porsche_928   \n",
       "7          http://dbpedia.org/resource/Porsche_924   \n",
       "\n",
       "                             rdf-schema#label  \\\n",
       "0  http://www.w3.org/2000/01/rdf-schema#label   \n",
       "1                            XMLSchema#string   \n",
       "2     http://www.w3.org/2001/XMLSchema#string   \n",
       "3                         Crawler-transporter   \n",
       "4                                   Ford GT40   \n",
       "5                                  Mazda MX-5   \n",
       "6                                 Porsche 928   \n",
       "7                                 Porsche 924   \n",
       "\n",
       "                                  rdf-schema#comment  \\\n",
       "0       http://www.w3.org/2000/01/rdf-schema#comment   \n",
       "1                                   XMLSchema#string   \n",
       "2            http://www.w3.org/2001/XMLSchema#string   \n",
       "3  The crawler-transporters are a pair of tracked...   \n",
       "4  The Ford GT40 is a high performance American-B...   \n",
       "5  The MX-5 also known as Miata in North America ...   \n",
       "6  The Porsche 928 is a sports-GT car that was so...   \n",
       "7  The Porsche 924 is a sports car produced by Po...   \n",
       "\n",
       "                            assembly_label  \\\n",
       "0     http://dbpedia.org/ontology/assembly   \n",
       "1                         XMLSchema#string   \n",
       "2  http://www.w3.org/2001/XMLSchema#string   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "5                        {Hiroshima|Japan}   \n",
       "6                      {Germany|Stuttgart}   \n",
       "7                                      NaN   \n",
       "\n",
       "                                            assembly  \\\n",
       "0               http://dbpedia.org/ontology/assembly   \n",
       "1                                          owl#Thing   \n",
       "2                http://www.w3.org/2002/07/owl#Thing   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5  {http://dbpedia.org/resource/Hiroshima|http://...   \n",
       "6  {http://dbpedia.org/resource/Germany|http://db...   \n",
       "7                                                NaN   \n",
       "\n",
       "                         automobilePlatform_label  \\\n",
       "0  http://dbpedia.org/ontology/automobilePlatform   \n",
       "1                                XMLSchema#string   \n",
       "2         http://www.w3.org/2001/XMLSchema#string   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "5                                Mazda N platform   \n",
       "6                                             NaN   \n",
       "7                                             NaN   \n",
       "\n",
       "                               automobilePlatform  \\\n",
       "0  http://dbpedia.org/ontology/automobilePlatform   \n",
       "1                                      Automobile   \n",
       "2          http://dbpedia.org/ontology/Automobile   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "5    http://dbpedia.org/resource/Mazda_N_platform   \n",
       "6                                             NaN   \n",
       "7                                             NaN   \n",
       "\n",
       "                           bodyStyle_label  \\\n",
       "0    http://dbpedia.org/ontology/bodyStyle   \n",
       "1                         XMLSchema#string   \n",
       "2  http://www.w3.org/2001/XMLSchema#string   \n",
       "3                                      NaN   \n",
       "4            {Coupé|Roadster (automobile)}   \n",
       "5                                      NaN   \n",
       "6                                    Coupé   \n",
       "7                     2+2 (car body style)   \n",
       "\n",
       "                                           bodyStyle  \\\n",
       "0              http://dbpedia.org/ontology/bodyStyle   \n",
       "1                                          owl#Thing   \n",
       "2                http://www.w3.org/2002/07/owl#Thing   \n",
       "3                                                NaN   \n",
       "4  {http://dbpedia.org/resource/Coup%C3%A9|http:/...   \n",
       "5                                                NaN   \n",
       "6             http://dbpedia.org/resource/Coup%C3%A9   \n",
       "7   http://dbpedia.org/resource/2+2_(car_body_style)   \n",
       "\n",
       "                               class_label  ...  \\\n",
       "0        http://dbpedia.org/ontology/class  ...   \n",
       "1                         XMLSchema#string  ...   \n",
       "2  http://www.w3.org/2001/XMLSchema#string  ...   \n",
       "3                                      NaN  ...   \n",
       "4      {Group 4 (racing)|Group 6 (racing)}  ...   \n",
       "5                    Roadster (automobile)  ...   \n",
       "6                             Grand tourer  ...   \n",
       "7                               Sports car  ...   \n",
       "\n",
       "                                 wheelbase  \\\n",
       "0    http://dbpedia.org/ontology/wheelbase   \n",
       "1                         XMLSchema#double   \n",
       "2  http://www.w3.org/2001/XMLSchema#double   \n",
       "3                                      NaN   \n",
       "4                                    2.413   \n",
       "5                                      NaN   \n",
       "6                                      2.5   \n",
       "7                                      NaN   \n",
       "\n",
       "                                     width  \\\n",
       "0        http://dbpedia.org/ontology/width   \n",
       "1                         XMLSchema#double   \n",
       "2  http://www.w3.org/2001/XMLSchema#double   \n",
       "3                                  34.7472   \n",
       "4                                    1.778   \n",
       "5                                      NaN   \n",
       "6                                     1.89   \n",
       "7                                    1.685   \n",
       "\n",
       "                                     point  \\\n",
       "0       http://www.georss.org/georss/point   \n",
       "1                         XMLSchema#string   \n",
       "2  http://www.w3.org/2001/XMLSchema#string   \n",
       "3                       28.58808 -80.65521   \n",
       "4                                      NaN   \n",
       "5                                      NaN   \n",
       "6                                      NaN   \n",
       "7                                      NaN   \n",
       "\n",
       "                         22-rdf-syntax-ns#type_label  \\\n",
       "0    http://www.w3.org/1999/02/22-rdf-syntax-ns#type   \n",
       "1                                   XMLSchema#string   \n",
       "2            http://www.w3.org/2001/XMLSchema#string   \n",
       "3  {automobile|mean of transportation|Product|_Fe...   \n",
       "4  {automobile|mean of transportation|Product|owl...   \n",
       "5  {automobile|mean of transportation|Product|owl...   \n",
       "6  {automobile|mean of transportation|Product|owl...   \n",
       "7  {automobile|mean of transportation|Product|owl...   \n",
       "\n",
       "                               22-rdf-syntax-ns#type  \\\n",
       "0    http://www.w3.org/1999/02/22-rdf-syntax-ns#type   \n",
       "1                                          owl#Class   \n",
       "2                http://www.w3.org/2002/07/owl#Class   \n",
       "3  {http://dbpedia.org/ontology/Automobile|http:/...   \n",
       "4  {http://dbpedia.org/ontology/Automobile|http:/...   \n",
       "5  {http://dbpedia.org/ontology/Automobile|http:/...   \n",
       "6  {http://dbpedia.org/ontology/Automobile|http:/...   \n",
       "7  {http://dbpedia.org/ontology/Automobile|http:/...   \n",
       "\n",
       "                                 wgs84_pos#lat  \\\n",
       "0  http://www.w3.org/2003/01/geo/wgs84_pos#lat   \n",
       "1                              XMLSchema#float   \n",
       "2       http://www.w3.org/2001/XMLSchema#float   \n",
       "3                                      28.5881   \n",
       "4                                          NaN   \n",
       "5                                          NaN   \n",
       "6                                          NaN   \n",
       "7                                          NaN   \n",
       "\n",
       "                                 wgs84_pos#long  \\\n",
       "0  http://www.w3.org/2003/01/geo/wgs84_pos#long   \n",
       "1                               XMLSchema#float   \n",
       "2        http://www.w3.org/2001/XMLSchema#float   \n",
       "3                                      -80.6552   \n",
       "4                                           NaN   \n",
       "5                                           NaN   \n",
       "6                                           NaN   \n",
       "7                                           NaN   \n",
       "\n",
       "                                   depiction_label  \\\n",
       "0              http://xmlns.com/foaf/0.1/depiction   \n",
       "1                                 XMLSchema#string   \n",
       "2          http://www.w3.org/2001/XMLSchema#string   \n",
       "3                          Crawler-Transporter.jpg   \n",
       "4                             GT40_at_Goodwood.jpg   \n",
       "5           2011_Mazda_MX-5_PRHT_--_04-28-2011.jpg   \n",
       "6                    1987_Porsche_928_S4_front.jpg   \n",
       "7  1977-1982_Porsche_924_coupe_(2011-04-28)_01.jpg   \n",
       "\n",
       "                                           depiction  \\\n",
       "0                http://xmlns.com/foaf/0.1/depiction   \n",
       "1                                          owl#Thing   \n",
       "2                http://www.w3.org/2002/07/owl#Thing   \n",
       "3  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "4  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "5  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "6  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "7  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "\n",
       "                                                name  \n",
       "0                     http://xmlns.com/foaf/0.1/name  \n",
       "1                                   XMLSchema#string  \n",
       "2            http://www.w3.org/2001/XMLSchema#string  \n",
       "3                                Crawler-transporter  \n",
       "4                                          Ford GT40  \n",
       "5  {Eunos Roadster|Mazda MX-5|Mazda MX-5 Miata|Ma...  \n",
       "6                                        Porsche 928  \n",
       "7                                        Porsche 924  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  primero necesito ver un poco el fichero. \n",
    "# aqui lo leo y muestro las primeras lineas\n",
    "path = 'C:/Users/sanchez_sanc/Desktop/data_analyst/Curso/3_Data_Wrangling/cursodata/'\n",
    "\n",
    "# Import GdP, Democracy score, Health and military expend, sugar per person and suicide\n",
    "auto0 = pd.read_csv(path + \"autos.csv\")\n",
    "auto0.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. la primera linea es el header, perfecto\n",
    ">2. la segunda y la tercera linea no se que son, miro mas despacio y veo que son \n",
    "las direcciones de donde estan los datos sueltos y los formatos de los datos\n",
    "Cuando vaya a utilizar el fichero tengo que usar la linea uno de header y las dos siguientes desecharlas \n",
    "como?\n",
    "\n",
    "!!! hay dos lineas que no hay que leer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es lo que pide el problema\n",
    ">- check if the field \"productionStartYear\" contains a year:\n",
    ">- check if the year is in range 1886-2014\n",
    ">- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "  \n",
    " 1. empiezo por buscar la columna y ver unas lineas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     http://dbpedia.org/ontology/productionStartYear\n",
       "1                                     XMLSchema#gYear\n",
       "2              http://www.w3.org/2001/XMLSchema#gYear\n",
       "3                                                 NaN\n",
       "4                           1964-01-01T00:00:00+02:00\n",
       "5                           1989-01-01T00:00:00+02:00\n",
       "6                           1977-01-01T00:00:00+02:00\n",
       "7                           1976-01-01T00:00:00+02:00\n",
       "8                           1982-01-01T00:00:00+02:00\n",
       "9                           1992-01-01T00:00:00+02:00\n",
       "10                          1965-01-01T00:00:00+02:00\n",
       "11                          1948-01-01T00:00:00+02:00\n",
       "12                          1996-01-01T00:00:00+02:00\n",
       "13                          1997-01-01T00:00:00+02:00\n",
       "14                          1957-01-01T00:00:00+02:00\n",
       "15                          1946-01-01T00:00:00+02:00\n",
       "16                          1969-01-01T00:00:00+02:00\n",
       "17                          1969-01-01T00:00:00+02:00\n",
       "18                          1970-01-01T00:00:00+02:00\n",
       "19                          1947-01-01T00:00:00+02:00\n",
       "Name: productionStartYear, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto1 = auto0.loc[:, \"productionStartYear\"]\n",
    "auto1.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veo que al menos hay un Nan y luego hay fechas, empiezan por year y luego mes... \n",
    "el problema pide que se convierta el formato a year unicamente\n",
    "intento saber que formato tiene y paso\n",
    "auto1[\"productionStartYear\"].dtype  da error porque\n",
    "las dos primeras lineas no son de datos, y se presupone todos los valores de la columna mismo tipo\n",
    "\n",
    "!!! hay valores que no son year\n",
    "!!! hay que convertir time a year guardando solo el year\n",
    "!!! sin tocar las otras columnas que tienen fechas\n",
    "!!! hay que filtar los year y\n",
    "    poner en good file los del  range 1886-2014 (filtro 1886-2014)\n",
    "    poner en el bad file los demas\n",
    "    \n",
    "!!! si la primera columna no es dbpedia.org hay que quitarla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mi logica seria\n",
    "leer el fichero\n",
    "quitar las lineas que no son dbpedia.org\n",
    "cambiar el formato de la columna [\"productionStartYear\"] a year, 4 cifras\n",
    "filtrar cada fila para ver si esta en el rango\n",
    "    si esta se manda a good file\n",
    "    si no esta se manda a bad file\n",
    "    \n",
    "ahora copio la solucion oficial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'autos.csv'   # aqui asocia el fichero input file con el nombre que le da en \n",
    "OUTPUT_GOOD = 'autos-valid.csv'  # aqui crea el fichero de salida de good\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'   # aqui crea el fichero de salida de bad\n",
    "\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "    # store data into lists for output\n",
    "    data_good = []  # crea lista data good\n",
    "    data_bad = []   # crea lista data bad\n",
    "    with open(input_file, \"r\") as f:   # abre el fichero \n",
    "        reader = csv.DictReader(f)    # llama reader a lo que esta leyendo\n",
    "        header = reader.fieldnames   # llama header a los fieldnames del reader, la primera linea del fichero\n",
    "        for row in reader:    # para cada linea que se encuentra en el fichero\n",
    "            # validate URI value\n",
    "            if row['URI'].find(\"dbpedia.org\") < 0:  # mira si en la columna URI se encuentra dbpedia\n",
    "                continue                            # no entiendo el < 0\n",
    "\n",
    "            ps_year = row['productionStartYear'][:4]     # aqui crea ps_year donde almacena las 4 primeras \n",
    "                                                         #cosas que encuentra en la row de la columna prodstart\n",
    "            try: # use try/except to filter valid items    # try ... except ver en la caja siguiente como funciona\n",
    "                ps_year = int(ps_year)                      #dice que ps_year se considere como int, \n",
    "                                                            #le quita asi la acpecion date para poder compararlo \n",
    "                                                            # con el rango de years\n",
    "                row['productionStartYear'] = ps_year    # ahora carga ps year en la linea que esta mirando \n",
    "                if (ps_year >= 1886) and (ps_year <= 2014):  # si el year esta entre las dos fechas \n",
    "                    data_good.append(row)                      #mete la linea en la lista good que ha creado antes\n",
    "                else:                                        # si el year NO esta entre las dos fechas\n",
    "                    data_bad.append(row)                        #mete la linea en la lista bad que ha creado antes\n",
    "            except ValueError: # non-numeric strings caught by exception   # esto es pareja con try, \n",
    "                            # si ha conseguido hacer try entero, no entra en except si no que pasa al if de arriba\n",
    "                            # si no ha conseguido hacer try entero, porque lo de ps_year no era un numero\n",
    "                            #entra en except y analiza el value error\n",
    "                if ps_year == 'NULL':               # si el error es que el valor es null entonces \n",
    "                    data_bad.append(row)            #mete la linea en la lista bad que ha creado antes\n",
    "\n",
    "    # Write processed data to output files\n",
    "    with open(output_good, \"w\") as good:\n",
    "        writer = csv.DictWriter(good, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_good:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    with open(output_bad, \"w\") as bad:\n",
    "        writer = csv.DictWriter(bad, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_bad:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "            \n",
    "# no entiendo muy bien lo que hace y desde luego no se como reproducirlo con test        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The try statement works as follows.\n",
    "\n",
    "First, the try clause (the statement(s) between the try and except keywords) is executed.\n",
    "\n",
    "If no exception occurs, the except clause is skipped and execution of the try statement is finished.\n",
    "\n",
    "If an exception occurs during execution of the try clause, the rest of the clause is skipped. Then if its type matches the exception named after the except keyword, the except clause is executed, and then execution continues after the try statement.\n",
    "\n",
    "If an exception occurs which does not match the exception named in the except clause, it is passed on to outer try statements; if no handler is found, it is an unhandled exception and execution stops with a message as shown above.\n",
    "\n",
    "A try statement may have more than one except clause, to specify handlers for different exceptions. At most one handler will be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "\n",
    "        #COMPLETE THIS FUNCTION\n",
    "\n",
    "\n",
    "\n",
    "    # This is just an example on how you can use csv.DictWriter\n",
    "    # Remember that you have to output 2 files\n",
    "    with open(output_good, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in YOURDATA:\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": # esto llama de alguna manera a un programa secundario?\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. auditing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_lines (input_file, skip):\n",
    "    for i in range(0, skip):\n",
    "        next (input_file)\n",
    "        \n",
    "def audit_country (input_file):\n",
    "    for row in input_file:\n",
    "        country = row ['country_label']\n",
    "        country=country.strip()\n",
    "        if (country == 'NULL') or (country == ''):\n",
    "            continue\n",
    "        if db.countries.find({'name':country}).count()!=1:\n",
    "                        print('Nof found:', country)\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18 Auditing uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "fieldname = 'wgs84_pos#lat'\n",
    "minval=-90\n",
    "maxval=90\n",
    "\n",
    "def skip_lines(input_file, skip):\n",
    "    for i in range (0, skip):\n",
    "        next(input_file)\n",
    "        \n",
    "        \n",
    "def is_number(S):\n",
    "    try:\n",
    "        float()\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def audit_float_field (v, counts):\n",
    "    v= v.strip()\n",
    "    if v=='NULL':\n",
    "        counts['nulls']+=1\n",
    "    elif v=='':\n",
    "        counts['empties']+=1   \n",
    "    elif is_array(v):\n",
    "        counts['arrays']+=1     \n",
    "    elif not is_number(v):\n",
    "        print ('Found non number:', v)\n",
    "    else\n",
    "        v= float (v)\n",
    "        if not ((minval<v) and (v<maxval)):\n",
    "            print ('Found out of range value:', v)     \n",
    "#        else:\n",
    "#            print v\n",
    "       \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Problem set data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. quiz auditing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up. In the first exercise we want you to audit\n",
    "the datatypes that can be found in some particular fields in the dataset.\n",
    "The possible types of values can be:\n",
    "- NoneType if the value is a string \"NULL\" or an empty string \"\"\n",
    "- list, if the value starts with \"{\"\n",
    "- int, if the value can be cast to int\n",
    "- float, if the value can be cast to float, but CANNOT be cast to int.\n",
    "   For example, '3.23e+07' should be considered a float because it can be cast\n",
    "   as float but int('3.23e+07') will throw a ValueError\n",
    "- 'str', for all other values\n",
    "\n",
    "The audit_file function should return a dictionary containing fieldnames and a \n",
    "SET of the types that can be found in the field. e.g.\n",
    "{\"field1\": set([type(float()), type(int()), type(str())]),\n",
    " \"field2\": set([type(str())]),\n",
    "  ....\n",
    "}\n",
    "The type() function returns a type object describing the argument given to the \n",
    "function. You can also use examples of objects to create type objects, e.g.\n",
    "type(1.1) for a float: see the test function below for examples.\n",
    "\n",
    "Note that the first three rows (after the header row) in the cities.csv file\n",
    "are not actual data points. The contents of these rows should note be included\n",
    "when processing data types. Be sure to include functionality in your code to\n",
    "skip over or detect these rows.\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\",\n",
    "          \"isPartOf_label\", \"areaCode\", \"populationTotal\", \"elevation\",\n",
    "          \"maximumElevation\", \"minimumElevation\", \"populationDensity\",\n",
    "          \"wgs84_pos#lat\", \"wgs84_pos#long\", \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
    "\n",
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {}\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for field in fields:\n",
    "        fieldtypes[field] = set()\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for i in range(3):\n",
    "            reader.next()\n",
    "        for row in reader:\n",
    "            for field in fields:\n",
    "                value = row[field]\n",
    "                if value == 'NULL' or value == '':\n",
    "                    fieldtypes[field].add(type(None))\n",
    "                elif value.startswith('{'):\n",
    "                    fieldtypes[field].add(list)\n",
    "                else:\n",
    "                    try:\n",
    "                        int(value)\n",
    "                        fieldtypes[field].add(int)\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            float(value)\n",
    "                            fieldtypes[field].add(float)\n",
    "                        except ValueError:\n",
    "                            fieldtypes[field].add(str)\n",
    "\n",
    "    return fieldtypes\n",
    "\n",
    "\n",
    "def test():\n",
    "    fieldtypes = audit_file(CITIES, FIELDS)\n",
    "\n",
    "    pprint.pprint(fieldtypes)\n",
    "\n",
    "    assert fieldtypes[\"areaLand\"] == set([type(1.1), type([]), type(None)])\n",
    "    assert fieldtypes['areaMetro'] == set([type(1.1), type(None)])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lo que tengo que hacer es\n",
    "1. la primera linea son los titulos de las columnas\n",
    "2. las tres lineas siguientes son info variadas que no me hacen falta ahora\n",
    "3. a partir de la 5 linea estan los datos a validar\n",
    "4. tengo que buscar para cada columna el tipo de datos que contiene y ponerlo en un diccionario\n",
    "en la pregunta me da la respuesta de que tipos hay y como llamarlos\n",
    "el codigo esta en la caja de arriba\n",
    "la respuesta en la caja de abajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'areaCode': set([<type 'NoneType'>, <type 'int'>, <type 'str'>]),\n",
    " 'areaLand': set([<type 'float'>, <type 'NoneType'>, <type 'list'>]),\n",
    " 'areaMetro': set([<type 'float'>, <type 'NoneType'>]),\n",
    " 'areaUrban': set([<type 'float'>, <type 'NoneType'>]),\n",
    " 'elevation': set([<type 'float'>, <type 'NoneType'>, <type 'list'>]),\n",
    " 'governmentType_label': set([<type 'NoneType'>, <type 'str'>]),\n",
    " 'homepage': set([<type 'NoneType'>, <type 'str'>]),\n",
    " 'isPartOf_label': set([<type 'NoneType'>, <type 'str'>, <type 'list'>]),\n",
    " 'maximumElevation': set([<type 'NoneType'>]),\n",
    " 'minimumElevation': set([<type 'NoneType'>]),\n",
    " 'name': set([<type 'NoneType'>, <type 'str'>, <type 'list'>]),\n",
    " 'populationDensity': set([<type 'float'>, <type 'NoneType'>, <type 'list'>]),\n",
    " 'populationTotal': set([<type 'NoneType'>, <type 'int'>]),\n",
    " 'timeZone_label': set([<type 'NoneType'>, <type 'str'>]),\n",
    " 'utcOffset': set([<type 'NoneType'>,\n",
    "                   <type 'int'>,\n",
    "                   <type 'str'>,\n",
    "                   <type 'list'>]),\n",
    " 'wgs84_pos#lat': set([<type 'float'>]),\n",
    " 'wgs84_pos#long': set([<type 'float'>])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fixing the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up.\n",
    "\n",
    "Since in the previous quiz you made a decision on which value to keep for the\n",
    "\"areaLand\" field, you now know what has to be done.\n",
    "\n",
    "Finish the function fix_area(). It will receive a string as an input, and it\n",
    "has to return a float representing the value of the area or None.\n",
    "You have to change the function fix_area. You can use extra functions if you\n",
    "like, but changes to process_file will not be taken into account.\n",
    "The rest of the code is just an example on how this function can be used.\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "\n",
    "def fix_area(area):\n",
    "    if area.startswith('{'):\n",
    "        area_list = area.replace('{', '').replace('}', '').split('|')\n",
    "        area0 = area_list[0]\n",
    "        area1 = area_list[1]\n",
    "        if len(area0) > len(area1):\n",
    "            area = float(area0)\n",
    "        else:\n",
    "            area = float(area1)\n",
    "    elif area == 'NULL' or '':\n",
    "        area = None\n",
    "    else:\n",
    "        area = float(area)\n",
    "\n",
    "    return area\n",
    "\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    # CHANGES TO THIS FUNCTION WILL BE IGNORED WHEN YOU SUBMIT THE EXERCISE\n",
    "    data = []\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to fix the area value\n",
    "            if \"areaLand\" in line:\n",
    "                line[\"areaLand\"] = fix_area(line[\"areaLand\"])\n",
    "            data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file(CITIES)\n",
    "\n",
    "    print \"Printing three example results:\"\n",
    "    for n in range(5,8):\n",
    "        pprint.pprint(data[n][\"areaLand\"])\n",
    "\n",
    "    assert data[3][\"areaLand\"] == None        \n",
    "    assert data[8][\"areaLand\"] == 55166700.0\n",
    "    assert data[20][\"areaLand\"] == 14581600.0\n",
    "    assert data[33][\"areaLand\"] == 20564500.0    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. fixing name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up.\n",
    "\n",
    "In the previous quiz you recognized that the \"name\" value can be an array (or\n",
    "list in Python terms). It would make it easier to process and query the data\n",
    "later if all values for the name are in a Python list, instead of being\n",
    "just a string separated with special characters, like now.\n",
    "\n",
    "Finish the function fix_name(). It will recieve a string as an input, and it\n",
    "will return a list of all the names. If there is only one name, the list will\n",
    "have only one item in it; if the name is \"NULL\", the list should be empty.\n",
    "The rest of the code is just an example on how this function can be used.\n",
    "\"\"\"\n",
    "import codecs\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "\n",
    "def fix_name(name):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "         \n",
    "    if name.startswith('{'):\n",
    "        name = name.replace('{', '').replace('}', '').split('|')\n",
    "    elif name == 'NULL':\n",
    "        name = []\n",
    "    else:\n",
    "        name = [name]\n",
    "    return name\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to fix the area value\n",
    "            if \"name\" in line:\n",
    "                line[\"name\"] = fix_name(line[\"name\"])\n",
    "            data.append(line)\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file(CITIES)\n",
    "\n",
    "    print \"Printing 20 results:\"\n",
    "    for n in range(20):\n",
    "        pprint.pprint(data[n][\"name\"])\n",
    "\n",
    "    assert data[14][\"name\"] == ['Negtemiut', 'Nightmute']\n",
    "    assert data[9][\"name\"] == ['Pell City Alabama']\n",
    "    assert data[3][\"name\"] == ['Kumhari']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Crossfield Auditing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up.\n",
    "\n",
    "If you look at the full city data, you will notice that there are couple of\n",
    "values that seem to provide the same information in different formats: \"point\"\n",
    "seems to be the combination of \"wgs84_pos#lat\" and \"wgs84_pos#long\". However,\n",
    "we do not know if that is the case and should check if they are equivalent.\n",
    "\n",
    "Finish the function check_loc(). It will recieve 3 strings: first, the combined\n",
    "value of \"point\" followed by the separate \"wgs84_pos#\" values. You have to\n",
    "extract the lat and long values from the \"point\" argument and compare them to\n",
    "the \"wgs84_pos# values, returning True or False.\n",
    "\n",
    "Note that you do not have to fix the values, only determine if they are\n",
    "consistent. To fix them in this case you would need more information. Feel free\n",
    "to discuss possible strategies for fixing this on the discussion forum.\n",
    "\n",
    "The rest of the code is just an example on how this function can be used.\n",
    "Changes to \"process_file\" function will not be taken into account for grading.\n",
    "\"\"\"\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "\n",
    "def check_loc(point, lat, longi):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    coordinates = point.split(' ')\n",
    "    return coordinates[0] == lat and coordinates[1] == longi\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra matadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to check the location\n",
    "            result = check_loc(line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
    "            if not result:\n",
    "                print \"{}: {} != {} {}\".format(line[\"name\"], line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
    "            data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    assert check_loc(\"33.08 75.28\", \"33.08\", \"75.28\") == True\n",
    "    assert check_loc(\"44.57833333333333 -91.21833333333333\", \"44.5783\", \"-91.2183\") == False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
